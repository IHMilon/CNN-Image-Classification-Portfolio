{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/IHMilon/CNN-Image-Classification-Portfolio/blob/main/VGG11_CIFAR10/Copy_of_VGG_on_CIFAR1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zwTiI9s17ZLu"
      },
      "source": [
        "# **Image Classification with VGG-like Architecture**\n",
        "In this project, I implement a **VGG-style CNN** from scratch and train it on the *CIFAR-10* dataset.  \n",
        "\n",
        "- Dataset: CIFAR-10 (60,000 images, 10 classes, 32×32 pixels)  \n",
        "- Model: Custom VGG-inspired architecture  \n",
        "- Goal: Achieve high classification accuracy with proper training pipeline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CNgeNkAUaR2P"
      },
      "source": [
        "## **Package Installation**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MYlO7SZVaQ-4"
      },
      "outputs": [],
      "source": [
        "!pip install torchprofile 1>/dev/null"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1DNRs8sC-vZa"
      },
      "source": [
        "## **Import Dependencies**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RTDW6vFw_NR6"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import random\n",
        "import time\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "import seaborn as sns\n",
        "from torchprofile import profile_macs\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from tqdm.auto import tqdm\n",
        "from PIL import Image\n",
        "\n",
        "\n",
        "import torch\n",
        "import torchvision\n",
        "from torch import nn\n",
        "import torch.optim as optim\n",
        "from torchvision import transforms\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.amp import autocast, GradScaler\n",
        "from torch.optim.lr_scheduler import OneCycleLR"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Ov73keMAao3"
      },
      "source": [
        "##  **Reproducibility**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EHNxE2tdA5v3"
      },
      "outputs": [],
      "source": [
        "seed_value = 10\n",
        "torch.manual_seed(seed_value)\n",
        "np.random.seed(seed_value)\n",
        "random.seed(seed_value)\n",
        "torch.cuda.manual_seed_all(seed_value)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ec0FbWYyiLg_"
      },
      "source": [
        "## **Device Setup**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-wZZtVLRTPGE"
      },
      "outputs": [],
      "source": [
        "device = torch.device('cuda'if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"Device is : {device}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZF6DpqoGB0H_"
      },
      "source": [
        "## **Data Augmentation**\n",
        "*To improve generalization, I apply some common image transformations to the CIFAR-10 training set. The test set is only converted to Tensor.*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3PabTy4cCpSw"
      },
      "outputs": [],
      "source": [
        "train_transform = transforms.Compose([\n",
        "    transforms.RandomCrop(32, padding=5),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomRotation(10),\n",
        "    transforms.ToTensor(),\n",
        "])\n",
        "\n",
        "test_transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ei1xHMdJy1ly"
      },
      "source": [
        "## **Loading the CIFAR-10 Dataset**\n",
        "\n",
        "We use the **torchvision's CIFAR-10 dataset** which contains **60,000 color images (32×32 pixels) across 10 classes**.\n",
        "\n",
        "- **Training Set:** *50,000 images (with data augmentation)*\n",
        "- **Test Set:** *10,000 images (for evaluation)*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W22NC4XYzABN"
      },
      "outputs": [],
      "source": [
        "train_data = torchvision.datasets.CIFAR10(root='./data', train = True, download = True, transform = train_transform)\n",
        "train_loader = DataLoader(train_data, batch_size = 128, shuffle = True, pin_memory = True)\n",
        "\n",
        "test_data = torchvision.datasets.CIFAR10(root='./data', train = False, download = True, transform = test_transform)\n",
        "test_loader = DataLoader(test_data, batch_size = 128, shuffle = False, pin_memory= True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "36R0-ouW1U5v"
      },
      "source": [
        "\n",
        "## **Inspect Training Batch**\n",
        "*we can verify the data type and shape of the train loader*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rO9qKLdH1tyi"
      },
      "outputs": [],
      "source": [
        "\n",
        "for images, targets in train_loader:\n",
        "    print(f\"Images shape: {images.shape}, and dtype: {images.dtype}\")\n",
        "    print(f\"Targets shape: {targets.shape}, and dtype: {targets.dtype}\")\n",
        "    break"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mJvA0LkIOuWJ"
      },
      "source": [
        "## **Defining the Model**\n",
        "\n",
        "We implement a **VGG-inspired CNN** where:\n",
        "- **Backbone:** Composed of eight `conv-bn-relu` blocks interleaved with four `maxpool`'s to downsample the feature map by 2^4 = 16 times.\n",
        "\n",
        "- **Classifier:** Uses **two fc (linear) layers** for final prediction."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8BUSXhNFPcu4"
      },
      "outputs": [],
      "source": [
        "class VGGM (nn.Module):\n",
        "    def __init__(self) -> None:\n",
        "        super().__init__()\n",
        "        self.backbone = nn.Sequential(\n",
        "              # Block 1\n",
        "              nn.Conv2d(3, 64, kernel_size = 3, padding = 1),\n",
        "              nn.BatchNorm2d(64),\n",
        "              nn.ReLU(),\n",
        "              nn.Conv2d(64, 64, kernel_size = 3, padding = 1),\n",
        "              nn.BatchNorm2d(64),\n",
        "              nn.ReLU(),\n",
        "              nn.MaxPool2d(2), #(B,64,16,16)\n",
        "\n",
        "              # Block 2\n",
        "              nn.Conv2d(64, 128, kernel_size = 3, padding = 1),\n",
        "              nn.BatchNorm2d(128),\n",
        "              nn.ReLU(),\n",
        "              nn.Conv2d(128, 128, kernel_size = 3, padding = 1),\n",
        "              nn.BatchNorm2d(128),\n",
        "              nn.ReLU(),\n",
        "              nn.MaxPool2d(2),  #(B,128,8,8)\n",
        "\n",
        "              # Block 3\n",
        "              nn.Conv2d(128, 256, kernel_size = 3, padding = 1),\n",
        "              nn.BatchNorm2d(256),\n",
        "              nn.ReLU(),\n",
        "              nn.Conv2d(256, 256, kernel_size =3, padding = 1),\n",
        "              nn.BatchNorm2d(256),\n",
        "              nn.ReLU(),\n",
        "              nn.MaxPool2d(2),  #(B,256,4,4)\n",
        "\n",
        "              # Block 4\n",
        "              nn.Conv2d(256, 512, kernel_size = 3, padding = 1),\n",
        "              nn.BatchNorm2d(512),\n",
        "              nn.ReLU(),\n",
        "              nn.Conv2d(512, 512, kernel_size = 3, padding = 1),\n",
        "              nn.BatchNorm2d(512),\n",
        "              nn.ReLU(),\n",
        "              nn.MaxPool2d(2)  #(B,512,2,2)\n",
        "              )\n",
        "\n",
        "        # Classifier\n",
        "        self.classifier = nn.Sequential(\n",
        "              nn.Linear(512, 128),\n",
        "              nn.BatchNorm1d(128),\n",
        "              nn.ReLU(),\n",
        "              nn.Dropout(0.5),\n",
        "              nn.Linear(128, 10)\n",
        "              )\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Backbone: (B, 3, 32, 32) --> (B, 512, 2, 2)\n",
        "        x = self.backbone(x)\n",
        "\n",
        "        # Avgpool: (B, 512, 2, 2) -->(B, 512)\n",
        "        x = x.mean(dim=(2,3))\n",
        "\n",
        "        # Classifier: (B, 512) --> (B, 10)\n",
        "        x = self.classifier(x)\n",
        "        return x\n",
        "\n",
        "model = VGGM().to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d4E4AEJ6UUEN"
      },
      "source": [
        "## **Model Size**\n",
        "The model size can be estimated by the number of trainable parameters:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hu-LXy_gWLo2"
      },
      "outputs": [],
      "source": [
        "total_params = 0\n",
        "for params in model.parameters():\n",
        "    if params.requires_grad:\n",
        "       total_params += params.numel()\n",
        "print(f\" Total Parameters is: {total_params/1000000:.2f} Millon\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d_ntlmxpX4IA"
      },
      "source": [
        "## **Computational Cost**\n",
        "\n",
        "The computation cost can be estimated by the number of multiply–accumulate operations (MACs):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v6TKgYtgY4-I"
      },
      "outputs": [],
      "source": [
        "x = torch.ones(1, 3, 32, 32).to(device)\n",
        "model.eval() # Set the model to evaluation mode\n",
        "macs = profile_macs(model, x)\n",
        "print(f\"Total number of MACs is: {macs/1000000:.2f} Million\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e8X1RwUeZ_v9"
      },
      "source": [
        "## **Training Setup**\n",
        "We use `CrossEntropyLoss` as the loss function, `AdamW` optimizer with weight decay for regularization, and the `OneCycleLR` scheduler for dynamic learning rate adjustment.\n",
        "Also Training is performed with `mixed precision` to accelerate computations and reduce GPU memory usage, following best practices in modern deep learning workflows."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i5xOBIdQdFqg"
      },
      "outputs": [],
      "source": [
        "Epochs = 25\n",
        "\n",
        "# loss function\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# optimizer\n",
        "optimizer = optim.AdamW(model.parameters(), lr = 1e-3, weight_decay = 5e-4)\n",
        "\n",
        "# LR Scheduler (OneCycleLR)\n",
        "scheduler = OneCycleLR(optimizer,\n",
        "            max_lr = 0.01,\n",
        "            steps_per_epoch = len(train_loader),\n",
        "            epochs = Epochs\n",
        "            )\n",
        "\n",
        "# Initialize the scaler\n",
        "scaler = GradScaler('cuda')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xtat1tt9i57R"
      },
      "source": [
        "## **Model Training**\n",
        "\n",
        "The VGG-like network is trained on **CIFAR-10** using **mixed precision** (`torch.amp`) for efficiency.  \n",
        "Each epoch includes:  \n",
        "\n",
        "- Forward pass with automatic loss scaling  \n",
        "- Backpropagation\n",
        "- Optimizer updates with learning rate scheduling  \n",
        "- Validation after each epoch to monitor generalization."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0uz0t_0zkF8i"
      },
      "outputs": [],
      "source": [
        "train_losses, train_accs = [], []\n",
        "test_losses, test_accs =[], []\n",
        "\n",
        "# Getting training time\n",
        "start_time = time.time()\n",
        "\n",
        "for epoch in tqdm(range(1, Epochs+1), desc = \"Epochs\"):\n",
        "\n",
        "    # Training loop\n",
        "    model.train()\n",
        "\n",
        "    # Training matrices\n",
        "    train_loss = 0\n",
        "    num_samples = 0\n",
        "    num_correct = 0\n",
        "\n",
        "    for images, labels in train_loader:\n",
        "        # Move data to the GPU\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "        # Zero out gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Forward pass with Mixed Precision\n",
        "        with autocast('cuda'):\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "        # scale the loss and calculate the gradiants\n",
        "        scaler.scale(loss).backward()\n",
        "        scaler.step(optimizer)\n",
        "        scaler.update()\n",
        "\n",
        "        # update the learning rate after each batch\n",
        "        scheduler.step()\n",
        "\n",
        "        # convert logits to class indices\n",
        "        predictions = outputs.argmax(dim=1)\n",
        "\n",
        "        # update the training matrices\n",
        "        train_loss += loss.item()\n",
        "        num_samples += labels.size(0)\n",
        "        num_correct += (predictions == labels).sum().item()\n",
        "\n",
        "    # training accuracy and losses\n",
        "    train_acc = (num_correct/num_samples)*100\n",
        "    train_losses.append(train_loss/len(train_loader))\n",
        "    train_accs.append(train_acc)\n",
        "\n",
        "\n",
        "    # validation loop\n",
        "    model.eval()\n",
        "\n",
        "    # test matrices\n",
        "    test_loss = 0\n",
        "    test_samples = 0\n",
        "    test_correct = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for images, labels in test_loader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            outputs = model(images)\n",
        "            loss = criterion (outputs, labels)\n",
        "\n",
        "            # Convert logits to class indecies\n",
        "            predictions = outputs.argmax(dim=1)\n",
        "\n",
        "            # update test matrices\n",
        "            test_loss += loss.item()\n",
        "            test_samples += labels.size(0)\n",
        "            test_correct += (predictions == labels).sum().item()\n",
        "\n",
        "        # Testing Accuracies and losses\n",
        "        test_acc = (test_correct / test_samples)*100\n",
        "        test_losses.append(test_loss/len(test_loader))\n",
        "        test_accs.append(test_acc)\n",
        "\n",
        "# Final model performance matrices\n",
        "print(f\"Training loss {train_losses[-1]:.3f}, Train Accuracy {train_accs[-1]:.2f}%\")\n",
        "print(f\"Test loss { test_losses[-1]:.3f}, Test Accuracy {test_accs[-1]:.2f}%\")\n",
        "\n",
        "# Calculate the Training Time\n",
        "end_time = time.time()\n",
        "total_time = end_time - start_time\n",
        "print(f\"\\nTotal time to train the model is {(total_time/60):.2f} Minutes\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PiHJoICFZ0oj"
      },
      "source": [
        "## **Training & Validation Loss/Accuracy**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gn8M1rE8aORb"
      },
      "outputs": [],
      "source": [
        "epoch_range = range(1,Epochs+1)\n",
        "plt.figure(figsize=(20,8))\n",
        "\n",
        "# Plot the Train and Val loss\n",
        "plt.subplot(1,2,1)\n",
        "plt.plot(epoch_range, train_losses, label = \"Train Loss\",marker='o')\n",
        "plt.plot(epoch_range, test_losses, label = \"Val Loss\", marker='o')\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.title(\"Training vs Validation Loss\")\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "\n",
        "# Plot the Train and Val Accuracy\n",
        "plt.subplot(1,2,2)\n",
        "plt.plot(epoch_range, train_accs, label = \"Train Acc\",marker='o')\n",
        "plt.plot(epoch_range, test_accs, label = \"Val Accs\",marker='o')\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.title(\"Training vs Validation Accuracy\")\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tFPah__1vI19"
      },
      "source": [
        "## **Visualization**\n",
        "We can visualize the model's prediction to see how the model truly performs:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BTdfdDcfx2q8"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(20,5))\n",
        "\n",
        "for i in range(20):\n",
        "    image, label = test_data[i]\n",
        "\n",
        "    # Model inference\n",
        "    model.eval()\n",
        "    with torch.inference_mode():\n",
        "         pred = model(image.unsqueeze(dim=0).to(device))\n",
        "         pred = pred.argmax(dim = 1)\n",
        "\n",
        "    # Convert CHW to HWC for visualization\n",
        "    image = image.permute(1,2,0)\n",
        "\n",
        "    # Convert class label to class name\n",
        "    label = test_data.classes[label]\n",
        "    pred = test_data.classes[pred]\n",
        "\n",
        "    # Visualize the images\n",
        "    plt.subplot(2, 10, i+1)\n",
        "    plt.imshow(image)\n",
        "    plt.title(f\"Pred: {pred}\"+ \"\\n\" + f\" Label: {label}\")\n",
        "    plt.axis('off')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Confusion Matrix**\n",
        "It visualizes the model's performance on the testset. And helps to identify which classes the model confuses the most."
      ],
      "metadata": {
        "id": "JqZxzAX6TGWC"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IszrteHSZOdp"
      },
      "outputs": [],
      "source": [
        "# Collect predictions and true labels\n",
        "true_labels = []\n",
        "predictions = []\n",
        "\n",
        "model.eval()\n",
        "with torch.inference_mode():\n",
        "    for images, labels in test_loader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        outputs = model(images)\n",
        "        pred = outputs.argmax(dim=1)\n",
        "        true_labels.extend(labels.cpu().numpy())\n",
        "        predictions.extend(pred.cpu().numpy())\n",
        "\n",
        "# Compute confusion matrix\n",
        "matrix = confusion_matrix(true_labels, predictions)\n",
        "\n",
        "# Get class name from label index\n",
        "class_name = test_data.classes\n",
        "\n",
        "# Plot heatmap\n",
        "plt.figure(figsize=(10,8))\n",
        "sns.heatmap(matrix, annot=True, fmt='d', xticklabels=class_name, yticklabels=class_name, cmap='Blues')\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('Actual')\n",
        "plt.title('Confusion Matrix')\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPKe+ubWaZQqLPN6eP552sd",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}